{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "import multiprocessing as mp\n",
    "\n",
    "def makedir(path):\n",
    "    Path(path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def majority_vote(x):\n",
    "    c = Counter(x)\n",
    "    value, count = c.most_common()[0]\n",
    "    return value\n",
    "def nothing(x):\n",
    "    if 1 != len(np.unique(x.values)):\n",
    "        assert False, \"error on aggregation\"\n",
    "    else:\n",
    "        return x.values[0]\n",
    "import itertools\n",
    "from operator import itemgetter\n",
    "    \n",
    "topics_to_consider = ['402', '403', '405', '407', '408', '410', '415', '416', '418', '420', '421', '427', '428', '431', '440', '442', '445', '448']\n",
    "topics_to_consider_moffat = ['402', '403', '405', '407', '408', '415', '416', '431', '440']\n",
    "#topics_to_consider = topics_to_consider_moffat[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "\n",
    "def save_json(obj, path):\n",
    "    with open(path, \"w\") as f:\n",
    "        json.dump(obj, f, indent=4)\n",
    "\n",
    "def load_json(path):\n",
    "    with open(path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "def save_pickle(obj, path):\n",
    "    with open(path, \"wb\") as f:\n",
    "        pickle.dump(obj, f)\n",
    "\n",
    "def load_pickle(path):\n",
    "    with open(path, \"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "    return data\n",
    "import os.path\n",
    "def file_exists(fname):\n",
    "    return os.path.isfile(fname) \n",
    "\n",
    "def makedir(PATH):\n",
    "    from pathlib import Path\n",
    "    Path(PATH).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def rmdir(PATH):\n",
    "    shutil.rmtree(PATH, ignore_errors=True)\n",
    "    \n",
    "import argparse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"-k\", type=int, default=3, nargs='+' )\n",
    "parser.add_argument(\"-b\", type=int, default=10, nargs='+')\n",
    "\n",
    "parser.add_argument(\"--which\", type=str, default='',choices=['all', 'adjacent', 'alleverysystem'], help='which pairs to rank') \n",
    "parser.add_argument(\"--rank\", type=str, default='',choices=['none', 'avgrank', 'borda','rrf','combMNZ','avgrankreversed'], help='how to rank pairs' )\n",
    "parser.add_argument(\"--preference\", type=str, default='',choices=['S100', 'ME', 'S2', 'S4', 'moffatratio','S100toPref','MEtoPref', 'S2toPref', 'S4toPref', 'TREC8'], help='how to evaluate pairs' )\n",
    "parser.add_argument(\"--topics\", type=str, default='',choices=['all', 'subsetmoffat'], help='which topics to use' )  \n",
    "parser.add_argument(\"--linearize\", type=str, default='',choices=['sortbywin', 'btl','btlscores'], help='how to linearize preferences' ) \n",
    "parser.add_argument(\"--server\", type=str, default='',choices=['mitel', 'bernini', 'local', 'gianluca'], help='where to run' ) \n",
    "parser.add_argument(\"--baseline\", type=int, default=0 ,choices=[0,1], help='is a baseline?' ) \n",
    "\n",
    "\n",
    "stt_example = \"--which all --rank borda --preference TREC8 --topics all --linearize sortbywin --server local -k 10 -b 3400\".split()\n",
    "#stt_example = \"--which adjacent --rank none --preference S100 --topics all --linearize sortbywin --server local -k 10 -b 10000 \".split()\n",
    "\n",
    "line_args = parser.parse_args(stt_example)\n",
    "#line_args = parser.parse_args()\n",
    "\n",
    "ARG_budgets = line_args.b\n",
    "ARG_ks = line_args.k\n",
    "ARG_which = line_args.which\n",
    "ARG_rank = line_args.rank\n",
    "ARG_preference = line_args.preference\n",
    "ARG_topics = line_args.topics\n",
    "ARG_linearize = line_args.linearize\n",
    "ARG_server = line_args.server\n",
    "ARG_baseline = line_args.baseline\n",
    "\n",
    "\n",
    "budget = ARG_budgets[0]\n",
    "k = ARG_ks[0]\n",
    "print(line_args)\n",
    "# for budget in ARG_budgets:\n",
    "#     for k in ARG_ks:\n",
    "#         print(f\"{budget} -- {k}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ARG_server=='mitel':\n",
    "    UNCOMPRESSED_PATH = '/mnt/sda/kevinr/IR/Uncompressed/AH99/input/'\n",
    "    QRELS_PATH = '/mnt/sda/kevinr/IR/'\n",
    "    DICT_AT_PATH = '/mnt/sda/kevinr/preference-on-a-budget/pers_script/dict_at/' \n",
    "    TREC_EVAL_PATH = '../IR/trec_eval-master/trec_eval'\n",
    "    DFIR_PATH = '/mnt/sda/kevinr/preference-on-a-budget/src/run_as_pickles/overcomplex/AH99.pickle'\n",
    "    if ARG_preference=='S100':\n",
    "        DFCROWD_PATH = '/mnt/sda/kevinr/preference-on-a-budget/src/S100.csv'\n",
    "    elif ARG_preference=='ME':\n",
    "        DFCROWD_PATH = '/mnt/sda/kevinr/preference-on-a-budget/src/ME.csv'\n",
    "    elif ARG_preference=='S2':\n",
    "        DFCROWD_PATH = '/mnt/sda/kevinr/preference-on-a-budget/src/S2.csv'\n",
    "    elif ARG_preference=='S4':\n",
    "        DFCROWD_PATH = '/mnt/sda/kevinr/preference-on-a-budget/src/S4.csv'\n",
    "    elif ARG_preference=='moffatratio':\n",
    "        DFCROWD_PATH = '/mnt/sda/kevinr/preference-on-a-budget/src/qrel_pref+rele+ratio-KRNormalized.csv'\n",
    "    elif ARG_preference=='S100toPref':\n",
    "        DFCROWD_PATH = '/mnt/sda/kevinr/preference-on-a-budget/src/S100toPreference/S100_pairwise_full_scores.csv'\n",
    "    elif ARG_preference=='MEtoPref':\n",
    "        DFCROWD_PATH = '/mnt/sda/kevinr/preference-on-a-budget/src/S100toPreference/ME_pairwise_full_scores.csv'\n",
    "    elif ARG_preference=='S2toPref':\n",
    "        DFCROWD_PATH = '/mnt/sda/kevinr/preference-on-a-budget/src/S100toPreference/S2_pairwise_full_scores.csv'\n",
    "    elif ARG_preference=='S4toPref':\n",
    "        DFCROWD_PATH = '/mnt/sda/kevinr/preference-on-a-budget/src/S100toPreference/S4_pairwise_full_scores.csv'\n",
    "    elif ARG_preference=='TREC8':\n",
    "        DFCROWD_PATH = '/mnt/sda/kevinr/preference-on-a-budget/src/S100.csv'\n",
    "    \n",
    "elif ARG_server=='bernini':\n",
    "    UNCOMPRESSED_PATH = '/home/kevinr/IR/Uncompressed/AH99/input/'\n",
    "    QRELS_PATH = '/home/kevinr/IR/'\n",
    "    DICT_AT_PATH = '/home/kevinr/preference-on-a-budget/pers_script/dict_at/' \n",
    "    TREC_EVAL_PATH = 'trec_eval'\n",
    "    DFIR_PATH = '/home/kevinr/preference-on-a-budget/src/run_as_pickles/overcomplex/AH99.pickle'\n",
    "    if ARG_preference=='S100':\n",
    "        DFCROWD_PATH = '/home/kevinr/preference-on-a-budget/src/S100.csv'\n",
    "    elif ARG_preference=='ME':\n",
    "        DFCROWD_PATH = '/home/kevinr/preference-on-a-budget/src/ME.csv'\n",
    "    elif ARG_preference=='S2':\n",
    "        DFCROWD_PATH = '/home/kevinr/preference-on-a-budget/src/S2.csv'\n",
    "    elif ARG_preference=='S4':\n",
    "        DFCROWD_PATH = '/home/kevinr/preference-on-a-budget/src/S4.csv'\n",
    "    elif ARG_preference=='moffatratio':\n",
    "        DFCROWD_PATH = '/home/kevinr/preference-on-a-budget/src/qrel_pref+rele+ratio-KRNormalized.csv'\n",
    "    elif ARG_preference=='S100toPref':\n",
    "        DFCROWD_PATH = '/home/kevinr/preference-on-a-budget/src/S100toPreference/S100_pairwise_full_scores.csv'\n",
    "    elif ARG_preference=='MEtoPref':\n",
    "        DFCROWD_PATH = '/home/kevinr/preference-on-a-budget/src/S100toPreference/ME_pairwise_full_scores.csv'\n",
    "    elif ARG_preference=='S2toPref':\n",
    "        DFCROWD_PATH = '/home/kevinr/preference-on-a-budget/src/S100toPreference/S2_pairwise_full_scores.csv'\n",
    "    elif ARG_preference=='S4toPref':\n",
    "        DFCROWD_PATH = '/home/kevinr/preference-on-a-budget/src/S100toPreference/S4_pairwise_full_scores.csv'\n",
    "    elif ARG_preference=='TREC8':\n",
    "        DFCROWD_PATH = '/home/kevinr/preference-on-a-budget/src/S100.csv'\n",
    "        \n",
    "elif ARG_server=='gianluca':\n",
    "    UNCOMPRESSED_PATH = '/home/kevin/IR/Uncompressed/AH99/input/'\n",
    "    QRELS_PATH = '/home/kevin/IR/'\n",
    "    DICT_AT_PATH = '/home/kevin/preference-on-a-budget/pers_script/dict_at/' \n",
    "    TREC_EVAL_PATH = 'trec_eval'\n",
    "    DFIR_PATH = '/home/kevin/preference-on-a-budget/src/run_as_pickles/overcomplex/AH99.pickle'\n",
    "    if ARG_preference=='S100':\n",
    "        DFCROWD_PATH = '/home/kevin/preference-on-a-budget/src/S100.csv'\n",
    "    elif ARG_preference=='ME':\n",
    "        DFCROWD_PATH = '/home/kevin/preference-on-a-budget/src/ME.csv'\n",
    "    elif ARG_preference=='S2':\n",
    "        DFCROWD_PATH = '/home/kevin/preference-on-a-budget/src/S2.csv'\n",
    "    elif ARG_preference=='S4':\n",
    "        DFCROWD_PATH = '/home/kevin/preference-on-a-budget/src/S4.csv'\n",
    "    elif ARG_preference=='moffatratio':\n",
    "        DFCROWD_PATH = '/home/kevin/preference-on-a-budget/src/qrel_pref+rele+ratio-KRNormalized.csv'\n",
    "    elif ARG_preference=='S100toPref':\n",
    "        DFCROWD_PATH = '/home/kevin/preference-on-a-budget/src/S100toPreference/S100_pairwise_full_scores.csv'\n",
    "    elif ARG_preference=='MEtoPref':\n",
    "        DFCROWD_PATH = '/home/kevin/preference-on-a-budget/src/S100toPreference/ME_pairwise_full_scores.csv'\n",
    "    elif ARG_preference=='S2toPref':\n",
    "        DFCROWD_PATH = '/home/kevin/preference-on-a-budget/src/S100toPreference/S2_pairwise_full_scores.csv'\n",
    "    elif ARG_preference=='S4toPref':\n",
    "        DFCROWD_PATH = '/home/kevin/preference-on-a-budget/src/S100toPreference/S4_pairwise_full_scores.csv'\n",
    "    elif ARG_preference=='TREC8':\n",
    "        DFCROWD_PATH = '/home/kevin/preference-on-a-budget/src/S100.csv'\n",
    "    \n",
    "elif ARG_server=='local':\n",
    "    UNCOMPRESSED_PATH = '../../../AAA_TREC-DATA/Uncompressed/AH99/input/'\n",
    "    QRELS_PATH = '../../../AAA_TREC-DATA/TREC-qrels'\n",
    "    DICT_AT_PATH = './pers_script/dict_at/'\n",
    "    BASE_PATH_FOLDER = './'\n",
    "    TREC_EVAL_PATH = 'trec_eval'\n",
    "    DFIR_PATH = '../../../AAA_TREC-DATA/run_as_pickles/overcomplex/AH99.pickle'\n",
    "\n",
    "    if ARG_preference=='S100':\n",
    "        DFCROWD_PATH = '../../../AAA_DATASET/CrowdData/Relevance-Assessment/S100.csv'\n",
    "    elif ARG_preference=='ME':\n",
    "        DFCROWD_PATH = '../../../AAA_DATASET/CrowdData/Relevance-Assessment/ME.csv'\n",
    "    elif ARG_preference=='S2':\n",
    "        DFCROWD_PATH = '../../../AAA_DATASET/CrowdData/Relevance-Assessment/S2.csv'\n",
    "    elif ARG_preference=='S4':\n",
    "        DFCROWD_PATH = '../../../AAA_DATASET/CrowdData/Relevance-Assessment/S4.csv'\n",
    "    elif ARG_preference=='moffatratio':\n",
    "        DFCROWD_PATH = '../../../AAA_DATASET/Moffat-and-co/OneDrive_1_25-11-2020/result_files/qrel_pref+rele+ratio.csv'\n",
    "    elif ARG_preference=='S100toPref':\n",
    "        DFCROWD_PATH = '../../src/S100toPreference/S100_pairwise_full_scores.csv'\n",
    "    elif ARG_preference=='S2toPref':\n",
    "        DFCROWD_PATH = '../../src/S100toPreference/S2_pairwise_full_scores.csv'\n",
    "    elif ARG_preference=='S4toPref':\n",
    "        DFCROWD_PATH = '../../src/S100toPreference/S4_pairwise_full_scores.csv'\n",
    "    elif ARG_preference=='MEtoPref':\n",
    "        DFCROWD_PATH = '../../src/S100toPreference/ME_pairwise_full_scores.csv'\n",
    "    elif ARG_preference=='TREC8':\n",
    "        DFCROWD_PATH = '../../../AAA_DATASET/CrowdData/Relevance-Assessment/S100.csv'\n",
    "else:\n",
    "    assert False, 'error on parameter server'\n",
    "\n",
    "TAG = f'experiment_k-{k}_b-{budget}_which-{ARG_which}_rank-{ARG_rank}_preference-{ARG_preference}_topics-{ARG_topics}_linearize-{ARG_linearize}' \n",
    "\n",
    "if ARG_baseline == 1:\n",
    "    SAVE_PATH = f\"./BASELINEexperiments/{TAG}/\"\n",
    "else:\n",
    "    SAVE_PATH = f\"./experiments/{TAG}/\"\n",
    "\n",
    "makedir(f'{SAVE_PATH}/partials/')\n",
    "makedir(f'{SAVE_PATH}/eval/ours')\n",
    "makedir(f'{SAVE_PATH}/eval/official')\n",
    "makedir(f'{SAVE_PATH}/correlations')\n",
    "makedir(f'{SAVE_PATH}/metrics')\n",
    "makedir(f'{SAVE_PATH}/qrels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcrowd = pd.read_csv(f'{DFCROWD_PATH}')\n",
    "if  ARG_preference=='S100':\n",
    "    dfcrowd = dfcrowd[['doc_id','S100_worker_id','S100_rel']]\n",
    "    dfcrowd.columns = ['doc_id','worker_id','rel']\n",
    "    dfcrowd.set_index('doc_id', inplace=True)\n",
    "if  ARG_preference=='ME':\n",
    "    dfcrowd = dfcrowd[['doc_id','ME_worker_id','ME_rel']]\n",
    "    dfcrowd.columns = ['doc_id','worker_id','rel']\n",
    "    dfcrowd.set_index('doc_id', inplace=True)\n",
    "if  ARG_preference=='S2':\n",
    "    dfcrowd = dfcrowd[['doc_id','S2_worker_id','S2_rel']]\n",
    "    dfcrowd.columns = ['doc_id','worker_id','rel']\n",
    "    dfcrowd.set_index('doc_id', inplace=True)\n",
    "if  ARG_preference=='S4':\n",
    "    dfcrowd = dfcrowd[['doc_id','S4_worker_id','S4_rel']]\n",
    "    dfcrowd.columns = ['doc_id','worker_id','rel']\n",
    "    dfcrowd.set_index('doc_id', inplace=True)\n",
    "if  ARG_preference=='moffatratio':\n",
    "    dfcrowd = dfcrowd[['topic','doc','ratio']]\n",
    "    dfcrowd.columns = ['topic','doc_id','rel']\n",
    "    dfcrowd.set_index('doc_id', inplace=True)\n",
    "if  ARG_preference=='S100toPref':\n",
    "    dfcrowd = dfcrowd[['topic','document','score']]\n",
    "    dfcrowd.columns = ['topic','doc_id','rel']\n",
    "    dfcrowd.set_index('doc_id', inplace=True)\n",
    "if  ARG_preference=='MEtoPref':\n",
    "    dfcrowd = dfcrowd[['topic','document','score']]\n",
    "    dfcrowd.columns = ['topic','doc_id','rel']\n",
    "    dfcrowd.set_index('doc_id', inplace=True)\n",
    "if  ARG_preference=='S2toPref':\n",
    "    dfcrowd = dfcrowd[['topic','document','score']]\n",
    "    dfcrowd.columns = ['topic','doc_id','rel']\n",
    "    dfcrowd.set_index('doc_id', inplace=True)\n",
    "if  ARG_preference=='S4toPref':\n",
    "    dfcrowd = dfcrowd[['topic','document','score']]\n",
    "    dfcrowd.columns = ['topic','doc_id','rel']\n",
    "    dfcrowd.set_index('doc_id', inplace=True)\n",
    "if  ARG_preference=='TREC8':\n",
    "    dfcrowd = dfcrowd[['topic','S100_worker_id','rel_TREC']]\n",
    "    dfcrowd.columns = ['topic','doc_id','rel']\n",
    "    dfcrowd.set_index('doc_id', inplace=True)\n",
    "    dfcrowd.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ARG_topics=='all':\n",
    "    topics_to_consider = topics_to_consider\n",
    "if ARG_topics=='subsetmoffat':\n",
    "    topics_to_consider = topics_to_consider_moffat[:]\n",
    "        \n",
    "topics = topics_to_consider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfirs = pd.read_pickle(f'{DICT_AT_PATH}/AH99_dict_at_{k}.pickle')\n",
    "dfir = pd.read_pickle(f'{DFIR_PATH}')#.reset_index()\n",
    "dfir = dfir.loc[dfir.index.get_level_values('topic').isin(topics_to_consider)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"--- select which couples to judge --- \"\"\"\n",
    "\n",
    "def which_all(i,topic):\n",
    "    global dfirs\n",
    "    sub_dfirs = dfirs[topic]\n",
    "    docs = list(sub_dfirs.keys())\n",
    "    docs = list(itertools.combinations(docs,2))\n",
    "    \n",
    "    save_pickle(docs,f'{SAVE_PATH}/partials/Which_{k}_{topic}.pkl')\n",
    "    return   \n",
    "\n",
    "def which_adjacent(i,topic):\n",
    "    order_couples = load_pickle(f'./pers_script/adj_couples/CouplesToJudgeADJ_{k}_{topic}.pkl')  \n",
    "    save_pickle(order_couples,f'{SAVE_PATH}/partials/Which_{k}_{topic}.pkl')\n",
    "    return   \n",
    "\n",
    "def which_alleverysystem(i,topic):\n",
    "    order_couples = load_pickle(f'./pers_script/all_couples_every_system/AllCouplesEverySystem_{k}_{topic}.pkl')  \n",
    "    save_pickle(order_couples,f'{SAVE_PATH}/partials/Which_{k}_{topic}.pkl')\n",
    "    return   \n",
    "\n",
    "\n",
    "#['all', 'adjacent', 'alleverysystem']\n",
    "print(f'\\t computing which couples to judge {ARG_which}')\n",
    "pool = mp.Pool(min(mp.cpu_count(),8))\n",
    "args = [(i,topic) for i,topic in enumerate(topics)]\n",
    "if ARG_which == 'all':\n",
    "    results = pool.starmap(which_all, args)\n",
    "elif ARG_which == 'adjacent':\n",
    "    results = pool.starmap(which_adjacent, args)\n",
    "elif ARG_which == 'alleverysystem':\n",
    "    results = pool.starmap(which_alleverysystem, args)\n",
    "else:\n",
    "    assert False, 'error on arg document score'\n",
    "pool.close()    \n",
    "print(f'\\t done computing which couples to judge {ARG_which}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### \"\"\"--- rank all couples and cut to budget --- \"\"\"\n",
    "\n",
    "def rank_avgrank(i,topic):\n",
    "    global budget, k, dfirs\n",
    "    # load couples\n",
    "    pool_couples = load_pickle(f'{SAVE_PATH}/partials/Which_{k}_{topic}.pkl')\n",
    "    # compute score for each document\n",
    "    sub_dfirs = dfirs[topic]\n",
    "    docs = list(sub_dfirs.keys())\n",
    "    doc_score = {}\n",
    "    for d in docs:\n",
    "        ar_d = np.average(sub_dfirs[d])\n",
    "        p_d = (k-ar_d)/k\n",
    "        doc_score[d] = p_d\n",
    "    # assign score to each couple\n",
    "    couples_score = {}\n",
    "    for d1, d2 in pool_couples:\n",
    "        score_d1 = doc_score.get(d1,-1)\n",
    "        score_d2 = doc_score.get(d2,-1)\n",
    "        score = 1-np.abs(score_d1-score_d2)\n",
    "        couples_score[(d1,d2)] = score\n",
    "    # sort\n",
    "    couples_score = [k for k,v in sorted(couples_score.items(), key=itemgetter(1))]\n",
    "    # cut at budget \n",
    "    couples_score = couples_score[:budget]\n",
    "    save_pickle(couples_score,f'./{SAVE_PATH}/partials/Rank_{k}_{topic}.pkl')\n",
    "    return\n",
    "\n",
    "def rank_borda(i,topic):\n",
    "    global budget, k, dfirs\n",
    "    # load couples\n",
    "    pool_couples = load_pickle(f'{SAVE_PATH}/partials/Which_{k}_{topic}.pkl')\n",
    "    # compute score for each document\n",
    "    sub_dfirs = dfirs[topic]\n",
    "    docs = list(sub_dfirs.keys())\n",
    "    doc_score = {}\n",
    "    for d in docs:\n",
    "        ar_d = np.average(sub_dfirs[d])\n",
    "        p_d = (k-ar_d)/k\n",
    "        doc_score[d] = p_d\n",
    "    # assign score to each couple\n",
    "    couples_score = {}\n",
    "    for d1, d2 in pool_couples:\n",
    "        score_d1 = doc_score.get(d1,-1)\n",
    "        score_d2 = doc_score.get(d2,-1)\n",
    "        score = 1-np.abs(score_d1-score_d2)\n",
    "        couples_score[(d1,d2)] = score\n",
    "    # sort\n",
    "    couples_score = [k for k,v in reversed(sorted(couples_score.items(), key=itemgetter(1)))]\n",
    "    # cut at budget \n",
    "    couples_score = couples_score[:budget]\n",
    "    save_pickle(couples_score,f'./{SAVE_PATH}/partials/Rank_{k}_{topic}.pkl')\n",
    "    return\n",
    "    \n",
    "def rank_none(i,topic):\n",
    "    # load couples\n",
    "    pool_couples = load_pickle(f'{SAVE_PATH}/partials/Which_{k}_{topic}.pkl')    \n",
    "    save_pickle(pool_couples,f'./{SAVE_PATH}/partials/Rank_{k}_{topic}.pkl')\n",
    "    return\n",
    "\n",
    "def rank_avgrankreversed(i,topic):\n",
    "    global budget, k, dfirs\n",
    "    # load couples\n",
    "    pool_couples = load_pickle(f'{SAVE_PATH}/partials/Which_{k}_{topic}.pkl')\n",
    "    # compute score for each document\n",
    "    sub_dfirs = dfirs[topic]\n",
    "    docs = list(sub_dfirs.keys())\n",
    "    doc_score = {}\n",
    "    for d in docs:\n",
    "        ar_d = np.average(sub_dfirs[d])\n",
    "        p_d = (k-ar_d)/k\n",
    "        doc_score[d] = p_d\n",
    "    # assign score to each couple\n",
    "    couples_score = {}\n",
    "    for d1, d2 in pool_couples:\n",
    "        score_d1 = doc_score.get(d1,-1)\n",
    "        score_d2 = doc_score.get(d2,-1)\n",
    "        score = 1-np.abs(score_d1-score_d2)\n",
    "        couples_score[(d1,d2)] = score\n",
    "    # sort\n",
    "    couples_score = [k for k,v in reversed(sorted(couples_score.items(), key=itemgetter(1)))]\n",
    "    # cut at budget \n",
    "    couples_score = couples_score[:budget]\n",
    "    save_pickle(couples_score,f'./{SAVE_PATH}/partials/Rank_{k}_{topic}.pkl')\n",
    "    return\n",
    "  \n",
    "    \n",
    "def rank_rff(i,topic):\n",
    "    global budget, k, dfirs\n",
    "    # load couples\n",
    "    pool_couples = load_pickle(f'{SAVE_PATH}/partials/Which_{k}_{topic}.pkl')\n",
    "    # compute score for each document\n",
    "    sub_dfirs = dfirs[topic]\n",
    "    docs = list(sub_dfirs.keys())\n",
    "    doc_score = {}\n",
    "    for d in docs:\n",
    "        p_d = np.sum([1/(0+x) for x in sub_dfirs[d]])\n",
    "        doc_score[d] = p_d\n",
    "    # assign score to each couple\n",
    "    couples_score = {}\n",
    "    for d1, d2 in pool_couples:\n",
    "        score_d1 = doc_score.get(d1,-1)\n",
    "        score_d2 = doc_score.get(d2,-1)\n",
    "        score = 1-np.abs(score_d1-score_d2)\n",
    "        couples_score[(d1,d2)] = score\n",
    "    # sort\n",
    "    couples_score = [k for k,v in sorted(couples_score.items(), key=itemgetter(1))]\n",
    "    # cut at budget \n",
    "    couples_score = couples_score[:budget]\n",
    "    save_pickle(couples_score,f'./{SAVE_PATH}/partials/Rank_{k}_{topic}.pkl')\n",
    "    return\n",
    "\n",
    "def rank_combMNZ(i,topic):\n",
    "    global budget, k, dfirs,dfirsscores\n",
    "    # load couples\n",
    "    pool_couples = load_pickle(f'{SAVE_PATH}/partials/Which_{k}_{topic}.pkl')\n",
    "    # compute score for each document\n",
    "    sub_dfirs = dfirs[topic]\n",
    "    sub_dfirsscores = dfirsscores[topic]\n",
    "    \n",
    "    docs = list(sub_dfirs.keys())\n",
    "    doc_score = {}\n",
    "    for d in docs:\n",
    "        num_pos = len(set(sub_dfirs[d]))\n",
    "        p_d = np.sum(sub_dfirsscores[d])\n",
    "        p_d = p_d * num_pos\n",
    "        doc_score[d] = p_d\n",
    "    # assign score to each couple\n",
    "    couples_score = {}\n",
    "    for d1, d2 in pool_couples:\n",
    "        score_d1 = doc_score.get(d1,-1)\n",
    "        score_d2 = doc_score.get(d2,-1)\n",
    "        score = 1-np.abs(score_d1-score_d2)\n",
    "        couples_score[(d1,d2)] = score\n",
    "    # sort\n",
    "    couples_score = [k for k,v in sorted(couples_score.items(), key=itemgetter(1))]\n",
    "    # cut at budget \n",
    "    couples_score = couples_score[:budget]\n",
    "    save_pickle(couples_score,f'./{SAVE_PATH}/partials/Rank_{k}_{topic}.pkl')\n",
    "    return\n",
    "    \n",
    "#['none', 'avgrank', 'borda', 'rff' ,'avgrankreversed']\n",
    "if ARG_rank == 'combMNZ':\n",
    "    dfirsscores = pd.read_pickle(f'{DICT_AT_PATH}/AH99_dict_at_{k}_rel.pickle')\n",
    "\n",
    "print(f'\\t computing rank {ARG_rank}')\n",
    "pool = mp.Pool(min(mp.cpu_count(),8))\n",
    "args = [(i,topic) for i,topic in enumerate(topics)]\n",
    "if ARG_rank == 'none':\n",
    "    results = pool.starmap(rank_none, args)\n",
    "elif ARG_rank == 'avgrank':\n",
    "    results = pool.starmap(rank_avgrank, args)\n",
    "elif ARG_rank == 'borda':\n",
    "    results = pool.starmap(rank_borda, args)\n",
    "elif ARG_rank == 'rrf':\n",
    "    results = pool.starmap(rank_rff, args)\n",
    "elif ARG_rank == 'combMNZ':\n",
    "    results = pool.starmap(rank_combMNZ, args)\n",
    "elif ARG_rank == 'avgrankreversed':\n",
    "    results = pool.starmap(rank_avgrankreversed, args)\n",
    "else:\n",
    "    assert False, 'error on arg rank couple'\n",
    "pool.close()    \n",
    "print(f'\\t done computing rank {ARG_rank}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"--- compute preferences -- take average judgment by crowd for all couples to judge --- \"\"\"\n",
    "\n",
    "if ARG_preference in ['S100', 'ME', 'S2', 'S4', 'moffatratio','TREC8']:\n",
    "    subdfcrowd = dfcrowd.reset_index()\n",
    "    subdfcrowd = subdfcrowd.groupby(['doc_id']).agg('mean').reset_index()\n",
    "    subdfcrowd = subdfcrowd[['doc_id','rel']]\n",
    "    docs = subdfcrowd['doc_id'].values\n",
    "    rels = subdfcrowd['rel'].values\n",
    "    subdfcrowd = {docs[x]:rels[x] for x in range(len(docs))}\n",
    "elif ARG_preference in ['S100toPref','MEtoPref','S2toPref','S4toPref']:\n",
    "    subdfcrowd = dfcrowd.copy()\n",
    "    subdfcrowd['topic'] = subdfcrowd['topic'].astype(str)\n",
    "    subdfcrowd.set_index('topic', inplace=True)\n",
    "else:\n",
    "    assert False, \"Error on preference_crowd\"\n",
    "    \n",
    "def preference_crowd(i,topic):\n",
    "    global  k\n",
    "    sub_couples = load_pickle(f'./{SAVE_PATH}/partials/Rank_{k}_{topic}.pkl')\n",
    "    \n",
    "    #sanitize for document rename\n",
    "    sub_couples = [ (d1.split(\"_\")[0],d2.split(\"_\")[0]) if (\"_\" in d1) else (d1,d2) for d1,d2 in sub_couples]\n",
    "    \n",
    "    #rank by average value\n",
    "    crowd_couples = [(d1, d2, subdfcrowd.get(d1,-1), subdfcrowd.get(d2,-1)) for d1,d2 in sub_couples]\n",
    "    \n",
    "    # compute preference\n",
    "    crowd_couples = [(d1,d2,d1) if v1>=v2 else (d1,d2,d2) for d1,d2,v1,v2 in crowd_couples]\n",
    "    \n",
    "    save_pickle(crowd_couples,f'./{SAVE_PATH}/partials/Preference_{k}_{topic}.pkl')\n",
    "    return \n",
    "\n",
    "def preference_crowdpref(i,topic):\n",
    "    global  k,subdfcrowd\n",
    "    sub_couples = load_pickle(f'./{SAVE_PATH}/partials/Rank_{k}_{topic}.pkl')\n",
    "    \n",
    "    #sanitize for document rename\n",
    "    sub_couples = [ (d1.split(\"_\")[0],d2.split(\"_\")[0]) if (\"_\" in d1) else (d1,d2) for d1,d2 in sub_couples]\n",
    "        \n",
    "    crowd_couples = subdfcrowd.loc[str(topic)]\n",
    "    crowd_couples = crowd_couples[['first', 'second', 'winner']]\n",
    "    crowd_couples = [tuple(x) for x in crowd_couples.to_numpy()]\n",
    "    \n",
    "    #crowd_couples = [(x,y,z) for x,y,z in crowd_couples if ((x,y) in sub_couples) or ((y,x) in sub_couples)]   \n",
    "    \n",
    "    save_pickle(crowd_couples,f'./{SAVE_PATH}/partials/Preference_{k}_{topic}.pkl')\n",
    "    return \n",
    "\n",
    "\n",
    "print(f'\\t computing preference {ARG_preference}')\n",
    "pool = mp.Pool(min(mp.cpu_count(),8))\n",
    "args = [(i,topic) for i,topic in enumerate(topics)]\n",
    "\n",
    "if ARG_preference in ['S100', 'ME', 'S2', 'S4', 'moffatratio','S100toPref','MEtoPref','S2toPref','S4toPref','TREC8']:\n",
    "    results = pool.starmap(preference_crowd, args)\n",
    "elif ARG_preference in ['nonefornow']:\n",
    "    results = pool.starmap(preference_crowdpref, args)\n",
    "else:\n",
    "    assert False, \"Error on preference_crowd\"\n",
    "\n",
    "pool.close()    \n",
    "print(f'\\t done computing preference {ARG_preference}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"--- linearize preferences  --- \"\"\"\n",
    "from mytoposort import comp_winlose,sort_by_wins\n",
    "from linearize import linearize\n",
    "\n",
    "def linearize_sortbywin(i,topic):\n",
    "    global k\n",
    "    preferences =  load_pickle(f'./{SAVE_PATH}/partials/Preference_{k}_{topic}.pkl')\n",
    "    partial_order = comp_winlose(preferences)\n",
    "    partial_order = sort_by_wins(partial_order)\n",
    "    scores = [i for i in range(len(partial_order))][::-1]\n",
    "    res = {}\n",
    "    res['scores'] = scores\n",
    "    res['partial_order'] = partial_order\n",
    "    save_pickle(res,f'./{SAVE_PATH}/partials/Linearize_{k}_{topic}.pkl')\n",
    "    return \n",
    "\n",
    "def linearize_BTL(i,topic):\n",
    "    global k\n",
    "    preferences =  load_pickle(f'./{SAVE_PATH}/partials/Preference_{k}_{topic}.pkl')\n",
    "    #print(preferences)\n",
    "    assert len(preferences)>0, f\"error on len for {topic}\"\n",
    "    partial_order,scores = linearize(preferences)\n",
    "    scores = [i for i in range(len(partial_order))][::-1]\n",
    "    res = {}\n",
    "    res['scores'] = scores\n",
    "    res['partial_order'] = partial_order\n",
    "    save_pickle(res,f'./{SAVE_PATH}/partials/Linearize_{k}_{topic}.pkl')\n",
    "    return \n",
    "\n",
    "def linearize_BTLScores(i,topic):\n",
    "    global k\n",
    "    preferences =  load_pickle(f'./{SAVE_PATH}/partials/Preference_{k}_{topic}.pkl')\n",
    "    assert len(preferences)>0, \"error on len\"\n",
    "    partial_order,scores = linearize(preferences)\n",
    "    res = {}\n",
    "    res['scores'] = scores\n",
    "    res['partial_order'] = partial_order\n",
    "    save_pickle(res,f'./{SAVE_PATH}/partials/Linearize_{k}_{topic}.pkl')\n",
    "    return \n",
    "\n",
    "# linearize_BTL(0,442)\n",
    "# assert False\n",
    "\n",
    "print(f'\\t computing linearize {ARG_linearize}')\n",
    "pool = mp.Pool(min(mp.cpu_count(),8))\n",
    "args = [(i,topic) for i,topic in enumerate(topics)]\n",
    "\n",
    "if ARG_linearize == 'sortbywin':\n",
    "    results = pool.starmap(linearize_sortbywin, args)\n",
    "elif ARG_linearize == 'btl':\n",
    "    results = pool.starmap(linearize_BTL, args)\n",
    "elif ARG_linearize == 'btlscores':\n",
    "    results = pool.starmap(linearize_BTLScores, args)    \n",
    "else:\n",
    "    assert False, 'error on arg rank couple'\n",
    "pool.close()    \n",
    "print(f'\\t done computing linearize {ARG_linearize}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"---compute qrels and eval  --- \"\"\"\n",
    "\n",
    "def linearizenotthrow(lista_ties, lista_off, scores):\n",
    "    def move_to_top(mylist, targetvalue):\n",
    "        res = mylist.copy()\n",
    "        res.insert(0, res.pop(res.index(targetvalue)))\n",
    "        return res\n",
    "    lista_off = list(lista_off)\n",
    "    lista_lin = []\n",
    "    lista_values = []\n",
    "    if len(lista_ties)==1:\n",
    "        lista_ties = [lista_ties]\n",
    "    for i,x in enumerate(lista_ties):\n",
    "        if len(x)==1:\n",
    "            lista_lin.append(x[0])\n",
    "            lista_values.append(scores[i])\n",
    "        else:\n",
    "            for elem in x:\n",
    "                 if elem in lista_off:\n",
    "                    x = move_to_top(x,elem)\n",
    "\n",
    "            for elem in x:\n",
    "                if elem in lista_off:\n",
    "                    lista_values = [x+1 for x in lista_values]\n",
    "                    lista_lin.append(elem)\n",
    "                    lista_values.append(scores[i]+1)\n",
    "                else:\n",
    "                    lista_lin.append(elem)\n",
    "                    lista_values.append(scores[i])\n",
    "    lista_values = [x+1 for x in lista_values]\n",
    "\n",
    "    return lista_lin, lista_values\n",
    "\n",
    "def compute_qrel_and_eval(z,run):\n",
    "    global dfir, k, topics\n",
    "    \n",
    "    df_qrel = []\n",
    "    for topic in topics:\n",
    "        #print(run, topic)\n",
    "        run_docs = dfir.loc[run].loc[topic]['list']['doc'].values[:k]\n",
    "        pos = load_pickle(f'./{SAVE_PATH}/partials/Linearize_{k}_{topic}.pkl')\n",
    "        scores = pos['scores']\n",
    "        po = pos['partial_order']\n",
    "                \n",
    "        linear_list, values_list = linearizenotthrow(lista_ties=po, lista_off=run_docs, scores=scores)\n",
    "        \n",
    "        for i in range(len((linear_list))):\n",
    "            df_qrel.append( (topic,0,linear_list[i],values_list[i])  )\n",
    "        \n",
    "    with open(f'./{SAVE_PATH}/qrels/qrels_{k}_{run}.txt', 'w') as fp:\n",
    "        fp.write(f'\\n'.join('{} {} {} {}'.format(x[0],x[1],x[2],x[3]) for x in df_qrel))\n",
    "    \n",
    "    os.system(f\"{TREC_EVAL_PATH} -q -m ndcg -M {k} {SAVE_PATH}/qrels/qrels_{k}_{run}.txt  {UNCOMPRESSED_PATH}/input.{run} > ./{SAVE_PATH}/eval/ours/{run}.txt \")\n",
    "    time.sleep(0.1)\n",
    "    os.system(f\"{TREC_EVAL_PATH} -q -m ndcg -M {k} {QRELS_PATH}/qrels.AH99.txt {UNCOMPRESSED_PATH}/input.{run} > ./{SAVE_PATH}/eval/official/{run}.txt \")\n",
    "    time.sleep(0.1)\n",
    "    return \n",
    "import time\n",
    "runs = np.unique(dfir.index.get_level_values('run'))\n",
    "\n",
    "print('\\t computing qrels and evaluating')\n",
    "pool = mp.Pool(min(mp.cpu_count(),8))\n",
    "#pool = mp.Pool(1)\n",
    "\n",
    "args = [(i,run)for i,run in enumerate(runs)]\n",
    "results = pool.starmap(compute_qrel_and_eval, args)\n",
    "pool.close()    \n",
    "#results = [item for sublist in results for item in sublist]\n",
    "print('\\t done computing qrels and evaluating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = f\"{SAVE_PATH}/qrels/\"\n",
    "files = [f for f in listdir(PATH) if (isfile(join(PATH, f))) & (f != \".DS_Store\")&(\"qrels_\" in f)&(\"orcl99man\" in f)]\n",
    "\n",
    "def read_specific(DATASET,budget):\n",
    "    dfev = pd.DataFrame(columns=['k','b','which','rank','preference','topics','linearize','kind','topic', 'system', 'metric','score'])\n",
    "    PATH = f'./server_experiments/{DATASET}/'\n",
    "    files = [f for f in listdir(PATH) if (isfile(join(PATH, f))) & (f != \".DS_Store\")&(\"correlation\" not in f)&(f\"{budget}\" in f)]\n",
    "\n",
    "    for f in files:#, desc='files', leave=False):\n",
    "        k = f.split(\"_\")[2].split(\"-\")[1]\n",
    "        b = f.split(\"_\")[3].split(\"-\")[1]\n",
    "        which = f.split(\"_\")[4].split(\"-\")[1]\n",
    "        rank = f.split(\"_\")[5].split(\"-\")[1]\n",
    "        preference = f.split(\"_\")[6].split(\"-\")[1]\n",
    "        topics = f.split(\"_\")[7].split(\"-\")[1]\n",
    "        linearize = f.split(\"_\")[8].split(\"-\")[1].split(\".\")[0]\n",
    "\n",
    "        if isfile(f'./{PATH}/{f}'):\n",
    "            cors = pd.read_csv(f'{PATH}/{f}')\n",
    "            cors['k'] = k\n",
    "            cors['b'] = b\n",
    "            cors['which'] = which\n",
    "            cors['rank'] = rank\n",
    "            cors['preference'] = preference\n",
    "            cors['topics'] = topics\n",
    "            cors['linearize'] = linearize\n",
    "            cors = cors[dfev.columns]\n",
    "            \n",
    "            dfev = pd.concat([dfev,cors])\n",
    "            \n",
    "    dfev['k'] = dfev['k'].astype(int)\n",
    "    dfev['b'] = dfev['b'].astype(int)\n",
    "    dfev['score'] = dfev['score'].astype(float)\n",
    "    dfev['label'] = dfev['which'] + \"-\" + dfev['rank'] + \"-\" + dfev['linearize']\n",
    "    \n",
    "    return dfev\n",
    "\n",
    "cors = read_specific('TREC8',budget)\n",
    "cors = cors[(cors['linearize']==ARG_linearize)\n",
    "           &(cors['which']==ARG_which)\n",
    "           &(cors['rank']==ARG_rank)]\n",
    "cors = cors.groupby(['kind','metric','system']).agg('mean').reset_index()\n",
    "\n",
    "\n",
    "for f in tqdm(files, desc='files', leave=False):\n",
    "    sysname = f.replace('qrels_10_','').replace('.txt','')\n",
    "    \n",
    "    subcors_trec =  cors[(cors['kind']=='TREC8')&(cors['system']==sysname)]['score'].values[0]\n",
    "    subcors_ours =  cors[(cors['kind']=='ours')&(cors['system']==sysname)]['score'].values[0]\n",
    "    \n",
    "\n",
    "    our_qrels = pd.read_csv(f\"{SAVE_PATH}/qrels/{f}\", sep=' ', header=None)\n",
    "    our_qrels.columns = ['topic','zero','doc','score_our']\n",
    "    our_qrels = our_qrels[['topic','doc','score_our']]\n",
    "\n",
    "    off_qrels = pd.read_csv(f\"{QRELS_PATH}/qrels.AH99.txt\", sep=' ', header=None)\n",
    "    off_qrels.columns = ['topic','zero','doc','score_off']\n",
    "    off_qrels = off_qrels[['topic','doc','score_off']]\n",
    "\n",
    "    merged = our_qrels.merge(off_qrels, how='inner', on=['topic','doc'])\n",
    "\n",
    "    # display(our_qrels.head())\n",
    "    # display(off_qrels.head())\n",
    "    #display(merged.head())\n",
    "\n",
    "    import seaborn as sns \n",
    "    import pylab as plt\n",
    "    from matplotlib.backends.backend_pdf import PdfPages\n",
    "    pd.set_option('display.max_columns', 500)\n",
    "    %matplotlib inline\n",
    "\n",
    "    sns.set_style('whitegrid')\n",
    "    plt.rcParams['figure.figsize']=(7,3)\n",
    "\n",
    "    import matplotlib\n",
    "    matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "    matplotlib.rcParams['ps.fonttype'] = 42\n",
    "\n",
    "    #merged = merged.head(10)\n",
    "    \n",
    "\n",
    "    pages = PdfPages(f\"../../plots/qrels/{sysname}.pdf\")\n",
    "    \n",
    "    fig, axs = plt.subplots(ncols=2, nrows=1)\n",
    "    \n",
    "    sns.boxplot(x=\"score_off\", y=\"score_our\", data=merged,\n",
    "                     boxprops=dict(facecolor='#FFFFFF', alpha=1, zorder = 0), ax=axs[0])\n",
    "\n",
    "    sns.violinplot(x=\"score_off\", y=\"score_our\", data=merged,\n",
    "                     inner='quartile', ax=axs[0])\n",
    "    \n",
    "    \n",
    "    x = cors[cors['kind']==\"TREC8\"]['score'].values\n",
    "    y = cors[cors['kind']==\"ours\"]['score'].values\n",
    "    \n",
    "    sns.regplot(x,y, fit_reg=True, ax=axs[1])\n",
    "\n",
    "    \n",
    "    sns.regplot([subcors_trec],[subcors_ours], fit_reg=False, ax=axs[1], color='red', marker='s')\n",
    "    \n",
    "    axs[1].set(xlim=(-0.05, 0.3),ylim=(-0., 0.25))\n",
    "    #plt.yticks([0.1, 0.2])\n",
    "    \n",
    "    axs[0].set(xlabel=f\"official\",ylabel=f\"pairwise\")\n",
    "    pages.savefig(bbox_inches='tight');pages.close()\n",
    "    plt.close()\n",
    "    assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"--- evaluate  --- \"\"\"\n",
    "\n",
    "df_ev = pd.DataFrame(columns=['kind','topic', 'system', 'metric','score'])\n",
    "\n",
    "def parses(path, kind):\n",
    "    df_ev = pd.DataFrame(columns=['kind','topic', 'system', 'metric','score'])\n",
    "    RUN_PATH = path\n",
    "    files = [f for f in listdir(RUN_PATH) if (isfile(join(RUN_PATH, f))) & (f != \".DS_Store\")]\n",
    "    for i, f in enumerate(files):\n",
    "        #print(f)\n",
    "        sys = f.replace('summary.{}.input.'.format(kind), '').replace('.txt', '')\n",
    "        df =  pd.read_csv(join(RUN_PATH, f), sep='\\t', header=None)\n",
    "        df.columns = ['metric', 'topic', 'score']\n",
    "        df['metric'] = [x.strip() for x in df['metric']]\n",
    "        df = df[df['metric']=='ndcg']\n",
    "        df = df[df['topic']!='all']\n",
    "        df['kind'] = kind\n",
    "        df['metric'] = 'ndcg'\n",
    "        df['system'] = sys\n",
    "               \n",
    "        df_ev = pd.concat([df_ev, df])\n",
    "        \n",
    "    return df_ev\n",
    "\n",
    "df_eval = pd.concat([\n",
    "parses(f'./{SAVE_PATH}/eval/official/', 'TREC8'),\n",
    "parses(f'./{SAVE_PATH}/eval/ours/', f'ours'),\n",
    "])\n",
    "\n",
    "df_eval = df_eval[df_eval['topic'].isin(topics)]\n",
    "df_eval['score'] = df_eval['score'].astype(float)\n",
    "df_eval.to_csv(f'{SAVE_PATH}/metrics/metric_{TAG}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''save correlation'''\n",
    "\n",
    "#from rbo import rbo\n",
    "from tauAP import tauAP, rank\n",
    "import scipy.stats\n",
    "\n",
    "\n",
    "ddres = pd.DataFrame(columns=['kind','x','y','rho','tau', 'tauAP','tau10'])\n",
    "\n",
    "for kind in ['topics-all','topics-moffat']:\n",
    "    if kind == 'topics-all':\n",
    "        df_plot = df_eval.groupby(['kind', 'system','metric']).agg('mean').reset_index()\n",
    "    else:\n",
    "        df_plot = df_eval[df_eval['topic'].isin(topics_to_consider_moffat)].groupby(['kind', 'system','metric']).agg('mean').reset_index()\n",
    "\n",
    "    ords = [('TREC8',f'ours')]\n",
    "    for i, (x_val, y_val) in enumerate(ords):\n",
    "        x = df_plot[df_plot['kind']==x_val]['score'].values \n",
    "        y = df_plot[df_plot['kind']==y_val]['score'].values\n",
    "\n",
    "        try:\n",
    "            rho, rhoval = sp.stats.pearsonr(x,y)\n",
    "            tau, tauval = sp.stats.kendalltau(x,y)\n",
    "\n",
    "            tauap = tauAP(x,y, top_heavy=True)\n",
    "\n",
    "            xten = x\n",
    "            yten = y\n",
    "            xten, yten = zip(*sorted(zip(xten, yten)))\n",
    "            xten = list(xten[::-1])\n",
    "            yten = list(yten[::-1])\n",
    "            xten = xten[:10]\n",
    "            yten = yten[:10]\n",
    "            tauten, tauvalten = sp.stats.kendalltau(xten,yten)      \n",
    "\n",
    "            ddres.loc[len(ddres)] = [kind,x_val, y_val, rho, tau, tauap, tauten]\n",
    "        except:\n",
    "            ddres.loc[len(ddres)] = [kind,x_val, y_val, np.nan, np.nan, np.nan, np.nan]\n",
    "    #ddres\n",
    "    ddres.to_csv(f'./{SAVE_PATH}/correlations/correlation_{TAG}.csv', index=False)\n",
    "    print(ddres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''delete folders'''\n",
    "import shutil\n",
    "rmdir(f\"{SAVE_PATH}/eval\")\n",
    "rmdir(f\"{SAVE_PATH}/partials\")\n",
    "rmdir(f\"{SAVE_PATH}/qrels\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \" \".join([str(x) for x in range(10, 101, 10)]) +\" \"+ \\\n",
    "# \" \".join([str(x) for x in range(100, 5001, 100)]) +\" \"+ \\\n",
    "# \" \".join([str(x) for x in range(10000, 100001, 10000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
